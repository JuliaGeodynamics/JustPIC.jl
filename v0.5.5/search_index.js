var documenterSearchIndex = {"docs":
[{"location":"interpolations/#Particles-interpolations","page":"Particles interpolations","title":"Particles interpolations","text":"","category":"section"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"For now, interpolations support only equidistant regular rectangular/cubic grids. Please file and issue if you would be interested in supporting other kind of grids.","category":"page"},{"location":"interpolations/#Grid-to-particle","page":"Particles interpolations","title":"Grid to particle","text":"","category":"section"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"Information from the grid is linearly interpolated to the particles. The one dimensional linear interpolation kernel (also referred as lerp) is defined as ","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"v_textp = t v_0  + (1 -t) v_1","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"where the t, v_0, and v_1 are graphically described below.","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"<img src=\"assets/lerp.png\" width=\"250\"  />","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"Numerically, it is more appropriately implemented as a double fma as it is slightly more accurate than a naive implementation:","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"v_p = fma(t, v1, fma(-t, v0, v0))","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"Bi- and tri-linear interpolation over a rectangular or cubic cells is thus nothing else than a chain of lerp kernels along the different dimensions of the cell. For example, the bilinear interpolation requires two lerps along the left and right sides of the cell, followed by a lerp on the horizontal direction; and trilinear interpolation requires two bilinear kernels and one lerp. ","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"N-linear interpolation is implemented in a recursive way to exploit compiler optimizations and reduce boilerplate code. Since in practical terms we will do up to tri-linear interpolation the maximum recursion depth is five, so that stack will never overflow.","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"We can interpolate an arbitrary field F onto the particles with the grid2particle function: ","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"using JustPIC, JustPIC._2D\n# define model domain\nnxcell, max_xcell, min_xcell = 24, 30, 12\nnx  = ny = 128\nLx  = Ly = 1.0\nxvi = range(0, Lx, length=n), range(0, Ly, length=n)\n# field F at the grid\nF  = [y for x in xv, y in yv]\n# instantiate empty `CellArray` \nFp, = init_cell_arrays(particles, Val(1));\n# interpolate F onto Fp\ngrid2particle!(Fp, xvi, F, particles);","category":"page"},{"location":"interpolations/#Particle-to-grid","page":"Particles interpolations","title":"Particle to grid","text":"","category":"section"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"Information on the particles is currently interpolated to the vertices of the grid cells with an inverse distance weighting interpolant","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"v_ij = fracsum^N_k=1 omega_k v_ksum^n_k=1 omega_k","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"where the weight is omega_i = d^-n, with d being the distance between the particle and the node, and n a integer number.","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"In shared memory environments (e.g. OpenMP parallelism or GPU programming), this particular interpolation often requires the use of atomic operations due to race conditions. In JustPIC we do avoid using atomic operations by parallelising over the grid nodes instead of the particles, i.e. we iterated over the nodes, with an inner iteration over the CellArrays neighbouring the i-th grid node.","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"This inteprolation is done with the particle2grid! function:","category":"page"},{"location":"interpolations/","page":"Particles interpolations","title":"Particles interpolations","text":"julia> particle2grid!(F, Fp, xvi, particles)","category":"page"},{"location":"field_advection2D/#Field-advection-in-2D","page":"Field advection in 2D","title":"Field advection in 2D","text":"","category":"section"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"First we load JustPIC","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"using JustPIC","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"and the correspondent 2D module (we could also use 3D by loading JustPIC._3D)","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"using JustPIC._2D","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"We need to specify what backend are we running our simulation on. For convenience we define the backend as a constant. In this case we use the CPU backend, but we could also use the CUDA (CUDABackend) or AMDGPU (AMDGPUBackend) backends.","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"const backend = JustPIC.CPUBackend","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"we define an analytical flow solution to advected our particles","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"vx_stream(x, y) =  250 * sin(π*x) * cos(π*y)\nvy_stream(x, y) = -250 * cos(π*x) * sin(π*y)","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"define the model domain","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"n  = 256        # number of nodes\nnx = ny = n-1   # number of cells in x and y\nLx = Ly = 1.0   # domain size\nxvi = xv, yv = range(0, Lx, length=n), range(0, Ly, length=n) # cell vertices\ndxi = dx, dy = xv[2] - xv[1], yv[2] - yv[1] # cell size\nxci = xc, yc = range(0+dx/2, Lx-dx/2, length=n-1), range(0+dy/2, Ly-dy/2, length=n-1) # cell centers","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"JustPIC uses staggered grids for the velocity field, so we need to define the staggered grid for Vx and Vy. We","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"grid_vx = xv, expand_range(yc) # staggered grid for Vx\ngrid_vy = expand_range(xc), yv # staggered grid for Vy","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"where expand_range is a helper function that extends the range of a 1D array by one cell size in each direction","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"function expand_range(x::AbstractRange)\n    dx = x[2] - x[1]\n    n = length(x)\n    x1, x2 = extrema(x)\n    xI = round(x1-dx; sigdigits=5)\n    xF = round(x2+dx; sigdigits=5)\n    range(xI, xF, length=n+2)\nend","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"Next we initialize the particles","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"nxcell    = 24 # initial number of particles per cell\nmax_xcell = 48 # maximum number of particles per cell\nmin_xcell = 14 # minimum number of particles per cell\nparticles = init_particles(\n    backend, nxcell, max_xcell, min_xcell, xvi...\n)","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"and the velocity and field we want to advect (on the staggered grid)","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"Vx = TA(backend)([vx_stream(x, y) for x in grid_vx[1], y in grid_vx[2]]);\nVy = TA(backend)([vy_stream(x, y) for x in grid_vy[1], y in grid_vy[2]]);\nT  = TA(backend)([y for x in xv, y in yv]); # defined at the cell vertices\nV  = Vx, Vy;\nnothing #hide","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"where TA(backend) will move the data to the specified backend (CPU, CUDA, or AMDGPU)","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"We also need to initialize the field T on the particles","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"particle_args = pT, = init_cell_arrays(particles, Val(1));\nnothing #hide","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"and we can use the function grid2particle! to interpolate the field T to the particles","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"grid2particle!(pT, xvi, T, particles);\nnothing #hide","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"we can now start the simulation","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"dt = min(dx / maximum(abs.(Array(Vx))),  dy / maximum(abs.(Array(Vy))));\nniter = 250\nfor it in 1:niter\n    advection!(particles, RungeKutta2(), V, (grid_vx, grid_vy), dt) # advect particles\n    move_particles!(particles, xvi, particle_args)                  # move particles in the memory\n    inject_particles!(particles, (pT, ), xvi)                       # inject particles if needed\n    particle2grid!(T, pT, xvi, particles)                           # interpolate particles to the grid\nend","category":"page"},{"location":"field_advection2D/#Pure-shear-in-2D","page":"Field advection in 2D","title":"Pure shear in 2D","text":"","category":"section"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"An example of two-dimensional pure shear flow is provided in this script. The velocity field is set to:","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"v_x = dotvarepsilon x","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"v_y = -dotvarepsilon y","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"where dotvarepsilon is the pure shear strain rate applied at the boundaries. A positive value of dotvarepsilon leads to horizontal extension, while negative values correspond to horizontal compression.","category":"page"},{"location":"field_advection2D/","page":"Field advection in 2D","title":"Field advection in 2D","text":"The ALE switch (Arbitrary Lagrangian Eulerian) allows to activate, or not, model box deformation. If  ALE=false, the model dimension remains constant over time. If ALE=true, the model domain is deformed with the background pure shear rate.","category":"page"},{"location":"mixed_CPU_GPU/#Mixed-CPU-and-GPU-computations","page":"Mixed GPU/CPU","title":"Mixed CPU and GPU computations","text":"","category":"section"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"If GPU memory is a limiting factor for your computation, it may be preferable to carry out particle operations on the CPU rather than on the GPU. This involves basically 4 steps:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"At the top of the script. The JustPIC backend must be set to CPU, in contrast with other employed packages (e.g. ParallelStencil):","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"const backend = JustPIC.CPUBackend ","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"At memory allocation stage. A copy of relevant CPU arrays must be allocated on the GPU memory. For example, phase ratios on mesh vertices:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"phv_GPU = @zeros(nx+1, ny+1, nz+1, celldims=(N_phases))","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"where N_phases is the number of different material phases and @zeros() allocates on the GPU.","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"Similarly, GPU arrays must be copied to CPU memory:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"V_CPU = (\n    x = zeros(nx+1, ny+2, nz+2),\n    y = zeros(nx+2, ny+1, nz+2),\n    z = zeros(nx+2, ny+2, nz+1),\n)","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"where zeros() allocates on the CPU memory.","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"At each time step. The particle will be stored on the CPU memory. It is hence necessary to transfer some information from the CPU to the GPU memory. For example, here's a transfer of phase proportions:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"phv_GPU.data .= CuArray(phase_ratios.vertex).data","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"!!! we explicitly write CuArray - would be better to have something more explicit like GPUArray - is there such a thing?","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"At each time step. Once velocity computation are finalised on the GPU, they need to be transferred to the CPU:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"V_CPU.x .= TA(backend)(V.x)\nV_CPU.y .= TA(backend)(V.y)\nV_CPU.z .= TA(backend)(V.z)","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"Advection can then be applied by calling the advection() function:","category":"page"},{"location":"mixed_CPU_GPU/","page":"Mixed GPU/CPU","title":"Mixed GPU/CPU","text":"advection!(particles, RungeKutta2(), values(V), (grid_vx, grid_vy, grid_vz), Δt)","category":"page"},{"location":"IO/#Checkpointing","page":"I/O","title":"Checkpointing","text":"","category":"section"},{"location":"IO/#Writing-checkpoint-files","page":"I/O","title":"Writing checkpoint files","text":"","category":"section"},{"location":"IO/","page":"I/O","title":"I/O","text":"It is customary to employ checkpointing during simulation that involve many time steps. A checkpoint file then needs to be written to disk. Such file allows for restarting a simulation from last checkpoint file written to disk. Moreover, checkpoint files may occupy a lost of disk space. Here is how to write essential particle information in a checkpoint file in jld2 format:","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"jldsave(\n    \"my_file.jld2\"; \n    particles     = Array(particles), \n    phases        = Array(phases), \n    phase_ratios  = Array(phase_ratios), \n    particle_args = Array.(particle_args),\n)","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"This will save particle information to the file my_file.jld2, which can be reused in order to restart a simulation.","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"If file size are huge, on may cast all the fields from particle structures into Float32. While this will spare disk space, it may hinder the reproducibility at restart. ","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"jldsave(\n    \"my_file.jld2\"; \n    particles     = Array(Float32, particles), \n    phases        = Array(Float32, phases), \n    phase_ratios  = Array(Float32, phase_ratios), \n    particle_args = Array.(Float32, particle_args),\n)","category":"page"},{"location":"IO/#Loading-a-checkpoint-file","page":"I/O","title":"Loading a checkpoint file","text":"","category":"section"},{"location":"IO/","page":"I/O","title":"I/O","text":"In order to restart a simulation, one needs to load the checkpoint file of interest. This is how to read the particle information from the checkpoint file my_file.jld2:","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"data          = load(\"my_file.jld2\")\nparticles     = TA(backend)(Float64, data[\"particles\"])\nphases        = TA(backend)(Float64, data[\"phases\"])\nphase_ratios  = TA(backend)(Float64, data[\"phase_ratios\"])\nparticle_args = TA(backend).(Float64, data[\"particle_args\"])","category":"page"},{"location":"IO/","page":"I/O","title":"I/O","text":"The function TA(backend) will automatically cast the data to the appropriate type, depending on the requested backend.  ","category":"page"},{"location":"particles/#Particles","page":"Particles","title":"Particles","text":"","category":"section"},{"location":"particles/#Memory-layout","page":"Particles","title":"Memory layout","text":"","category":"section"},{"location":"particles/","page":"Particles","title":"Particles","text":"Particles stored in CellArrays objects from CellArrays.jl and are constantly sorted by their parent cell to avoid a loss of spatial locality with time.","category":"page"},{"location":"particles/#Particle-objects","page":"Particles","title":"Particle objects","text":"","category":"section"},{"location":"particles/","page":"Particles","title":"Particles","text":"There are three type of AbstractParticles types:","category":"page"},{"location":"particles/","page":"Particles","title":"Particles","text":"Particles is the basic type used to advect and track information on the whole domain of our model. The dimension of the CellArrays has to match the dimension of the model.\nPassiveMarkers is a set of particles where their initial position is defined by the user. These particles are only advected and are not meant to have any feedback with the simulation; their purpose is to track the history of any arbitrary field(s) throughout the simulation.\nMarkerChain is a one or two dimensional chain of particles, used to track surfaces / interfaces.","category":"page"},{"location":"particles/#Simulation-particles","page":"Particles","title":"Simulation particles","text":"","category":"section"},{"location":"particles/","page":"Particles","title":"Particles","text":"struct Particles{Backend,N,M,I,T1,T2} <: AbstractParticles\n    coords::NTuple{N,T1}\n    index::T2\n    nxcell::I\n    max_xcell::I\n    min_xcell::I\n    np::I\nend","category":"page"},{"location":"particles/","page":"Particles","title":"Particles","text":"Where coords is a tuple containing the coordinates of the particles; index is a BitArray where true if in the correspondent CellArray there is an active particle, otherwise false; nxcell, min_xcell, max_xcell are the initial, minimum and maximum number of particles per cell; and, np is the initial number of particles.","category":"page"},{"location":"particles/#Passive-markers","page":"Particles","title":"Passive markers","text":"","category":"section"},{"location":"particles/","page":"Particles","title":"Particles","text":"struct MarkerChain{Backend,N,M,I,T1,T2,TV} <: AbstractParticles\n    coords::NTuple{N,T1}\n    index::T2\n    cell_vertices::TV \n    max_xcell::I\n    min_xcell::I\nend","category":"page"},{"location":"particles/","page":"Particles","title":"Particles","text":"Where coords is a tuple containing the coordinates of the particles; index is an BitArray where true if in the correspondent CellArray there is an active particle, otherwise false; cell_vertices is the lower-left corner ((x,) in 2D, (x,y) in 3D) of the cell containing those particles;and, min_xcell, max_xcell are theminimum and maximum number of particles per cell.","category":"page"},{"location":"particles/#Marker-chain","page":"Particles","title":"Marker chain","text":"","category":"section"},{"location":"particles/","page":"Particles","title":"Particles","text":"struct PassiveMarkers{Backend,T} <: AbstractParticles\n    coords::T\n    np::Int64\nend","category":"page"},{"location":"particles/","page":"Particles","title":"Particles","text":"Where coords is a tuple containing the coordinates of the particles; and np is the number of passive markers.","category":"page"},{"location":"velocity_interpolation/#Velocity-interpolation","page":"Velocity interpolation","title":"Velocity interpolation","text":"","category":"section"},{"location":"velocity_interpolation/#Linear","page":"Velocity interpolation","title":"Linear","text":"","category":"section"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"The default interpolation scheme is a bi-linear (2D) or tri-linear (3D) interpolant.","category":"page"},{"location":"velocity_interpolation/#LinP","page":"Velocity interpolation","title":"LinP","text":"","category":"section"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Velocity interpolation from Pusok et al. 2017. The velocity at the m-th particle is given by","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m = A u_L + (1-A) u_P","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"where u_L is the bi or tri-linear interpolation from the velocity nodes to the particle, u_P is the bi or tri-linear interpolation from the pressure nodes to the particle, and A=23 is an empirical coefficient.","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"<img src=\"assets/LinP.png\" width=\"700\"  />","category":"page"},{"location":"velocity_interpolation/#Modified-Quadratic-Spline-MQS","page":"Velocity interpolation","title":"Modified Quadratic Spline MQS","text":"","category":"section"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Velocity interpolation from Gerya et al. 2021. The scheme guarantee bi-linear interpolation of partial u_ipartial x_i from pressure nodes where they are defined by solving (in)compressible continuity equation.","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Example for the u_x component in 2D:","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"<img src=\"assets/MQs.png\" width=\"700\"  />","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Step 1 Compute the normalized distances between particle and left-bottom corner of the cell:","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"t_x = fracx_m - xc_jDelta x","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"t_y = fracy_m - yc_jDelta y","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Step 2 Compute u_x velocity with bi-linear scheme for the bottom and top","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m^(13) = u_ij t_x + u_ij+1 t_x","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m^(23) = u_i+1j t_x + u_i+1j+1 t_x","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Step 3 Compute u_x of the marker with bi-linear scheme in vertical direction","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m^(13) = u_m^(13) + frac12 (t_x-frac12)^2 (u_ij-1-2u_ij+u_ij-1)","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m^(24) = u_m^(24) + frac12 (t_x-frac12)^2 (u_i+1j-1-2u_i+1j+u_i+1j-1)","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"Step 4 Compute u_x  vx of the marker with bi-linear scheme in vertical direction","category":"page"},{"location":"velocity_interpolation/","page":"Velocity interpolation","title":"Velocity interpolation","text":"u_m = (1-t_y) u_m^(13)+(t_y) u_m^(24)","category":"page"},{"location":"API/#API","page":"Public API","title":"API","text":"","category":"section"},{"location":"API/","page":"Public API","title":"Public API","text":"JustPIC._2D.setelement!\nJustPIC._3D.element\nJustPIC._3D.setelement!\nJustPIC._3D.@idx\nJustPIC._2D.@idx\nJustPIC._2D.element\nJustPIC._3D.lerp\nJustPIC._2D.lerp","category":"page"},{"location":"API/#JustPIC._3D.@idx","page":"Public API","title":"JustPIC._3D.@idx","text":"@idx(args...)\n\nMake a linear range from 1 to args[i], with i ∈ [1, ..., n]\n\n\n\n\n\n","category":"macro"},{"location":"API/#JustPIC._2D.@idx","page":"Public API","title":"JustPIC._2D.@idx","text":"@idx(args...)\n\nMake a linear range from 1 to args[i], with i ∈ [1, ..., n]\n\n\n\n\n\n","category":"macro"},{"location":"API/#JustPIC._3D.lerp","page":"Public API","title":"JustPIC._3D.lerp","text":"lerp(v, t::NTuple{nD,T}) where {nD,T}\n\nLinearly interpolates the value v between the elements of the tuple t. This function is specialized for tuples of length nD.\n\nArguments\n\nv: The value to be interpolated.\nt: The tuple of values to interpolate between.\n\n\n\n\n\n","category":"function"},{"location":"API/#JustPIC._2D.lerp","page":"Public API","title":"JustPIC._2D.lerp","text":"lerp(v, t::NTuple{nD,T}) where {nD,T}\n\nLinearly interpolates the value v between the elements of the tuple t. This function is specialized for tuples of length nD.\n\nArguments\n\nv: The value to be interpolated.\nt: The tuple of values to interpolate between.\n\n\n\n\n\n","category":"function"},{"location":"field_advection3D/#Field-advection-in-3D","page":"Field advection in 3D","title":"Field advection in 3D","text":"","category":"section"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"First we load JustPIC","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"using JustPIC","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"and the corresponding 3D module","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"using JustPIC._3D","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"We need to specify what backend are we running our simulation on. For convenience we define the backend as a constant. In this case we use the CPU backend, but we could also use the CUDA (CUDABackend) or AMDGPU (AMDGPUBackend) backends.","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"const backend = JustPIC.CPUBackend","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"we define an analytical flow solution to advected our particles","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"vx_stream(x, z) =  250 * sin(π*x) * cos(π*z)\nvy_stream(x, z) =  0.0\nvz_stream(x, z) = -250 * cos(π*x) * sin(π*z)","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"define the model domain","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"n  = 64             # number of nodes\nnx  = ny = nz = n-1 # number of cells in x and y\nLx  = Ly = Lz = 1.0 # domain size\nni  = nx, ny, nz\nLi  = Lx, Ly, Lz\n\nxvi = xv, yv, zv = ntuple(i -> range(0, Li[i], length=n), Val(3)) # cell vertices\nxci = xc, yc, zc = ntuple(i -> range(0+dxi[i]/2, Li[i]-dxi[i]/2, length=ni[i]), Val(3)) # cell centers\ndxi = dx, dy, dz = ntuple(i -> xvi[i][2] - xvi[i][1], Val(3)) # cell size","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"JustPIC uses staggered grids for the velocity field, so we need to define the staggered grid for Vx and Vy. We","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"grid_vx = xv              , expand_range(yc), expand_range(zc) # staggered grid for Vx\ngrid_vy = expand_range(xc), yv              , expand_range(zc) # staggered grid for Vy\ngrid_vz = expand_range(xc), expand_range(yc), zv               # staggered grid for Vy","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"where expand_range is a helper function that extends the range of a 1D array by one cell size in each direction","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"function expand_range(x::AbstractRange)\n    dx = x[2] - x[1]\n    n = length(x)\n    x1, x2 = extrema(x)\n    xI = round(x1-dx; sigdigits=5)\n    xF = round(x2+dx; sigdigits=5)\n    range(xI, xF, length=n+2)\nend","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"Next we initialize the particles","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"nxcell    = 24 # initial number of particles per cell\nmax_xcell = 48 # maximum number of particles per cell\nmin_xcell = 14 # minimum number of particles per cell\nparticles = init_particles(\n    backend, nxcell, max_xcell, min_xcell, xvi...\n)","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"and the velocity and field we want to advect (on the staggered grid)","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"Vx = TA(backend)([vx_stream(x, z) for x in grid_vx[1], y in grid_vx[2], z in grid_vx[3]])\nVy = TA(backend)([vy_stream(x, z) for x in grid_vy[1], y in grid_vy[2], z in grid_vy[3]])\nVz = TA(backend)([vz_stream(x, z) for x in grid_vz[1], y in grid_vz[2], z in grid_vz[3]])\nT  = TA(backend)([z for x in xv, y in yv, z in zv]) # defined at the cell vertices\nV  = Vx, Vy, Vz","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"where TA(backend) will move the data to the specified backend (CPU, CUDA, or AMDGPU)","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"We also need to initialize the field T on the particles","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"particle_args = pT, = init_cell_arrays(particles, Val(1));","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"and we can use the function grid2particle! to interpolate the field T to the particles","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"grid2particle!(pT, xvi, T, particles)","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"we can now start the simulation","category":"page"},{"location":"field_advection3D/","page":"Field advection in 3D","title":"Field advection in 3D","text":"dt = min(dx / maximum(abs.(Vx)), dy / maximum(abs.(Vy)), dz / maximum(abs.(Vz))) / 2\n\nniter = 250\nfor it in 1:niter\n    advection!(particles, RungeKutta2(), V, (grid_vx, grid_vy, grid_vz), dt) # advect particles\n    move_particles!(particles, xvi, particle_args)                           # move particles in the memory\n    inject_particles!(particles, (pT, ), xvi)                                # inject particles if needed\n    particle2grid!(T, pT, xvi, particles)                                    # interpolate particles to the grid\nend","category":"page"},{"location":"field_advection2D_MPI/#Field-advection-in-2D-using-MPI","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"","category":"section"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"As usual, we start loading JustPIC.jl modules and specifying the backend","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"using JustPIC, JustPIC._2D\nconst backend = JustPIC.CPUBackend","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"and we define the usual analytical flow solution","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"vx_stream(x, y) =  250 * sin(π*x) * cos(π*y)\nvy_stream(x, y) = -250 * cos(π*x) * sin(π*y)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"This time, we also need to load MPI.jl and ImplicitGlobalGrid.jl to handle the MPI communication between the different CPU's","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"using ImplicitGlobalGrid\nusing MPI: MPI","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"Then we define the model domain","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"n  = 256        # number of nodes\nnx = ny = n-1   # number of cells in x and y\nLx = Ly = 1.0   # domain size","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":", initialize the global grid","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"me, dims, = init_global_grid(n-1, n-1, 1; init_MPI=MPI.Initialized() ? false : true)\ndxi = dx, dy = Lx /(nx_g()-1), Ly / (ny_g()-1)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"and the arrays local to each MPI rank","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"# nodal vertices\nxvi = xv, yv = let\n    dummy = zeros(n, n) \n    xv  = TA(backend)([x_g(i, dx, dummy) for i in axes(dummy, 1)])\n    yv  = TA(backend)([y_g(i, dx, dummy) for i in axes(dummy, 2)])\n    xv, yv\nend\n# nodal centers\nxci = xc, yc = let\n    dummy = zeros(nx, ny) \n    xc  = @zeros(nx) \n    xc .= TA(backend)([x_g(i, dx, dummy) for i in axes(dummy, 1)])\n    yc  = TA(backend)([y_g(i, dx, dummy) for i in axes(dummy, 2)])\n    xc, yc\nend\n# staggered grid for the velocity components\ngrid_vx = xv, add_ghost_nodes(yc, dy, (0.0, Ly))\ngrid_vy = add_ghost_nodes(xc, dx, (0.0, Lx)), yv","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"And we continue with business as usual","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"nxcell    = 24 # initial number of particles per cell\nmax_xcell = 48 # maximum number of particles per cell\nmin_xcell = 14 # minimum number of particles per cell\nparticles = init_particles(\n    backend, nxcell, max_xcell, min_xcell, xvi...\n)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"and the velocity and field we want to advect (on the staggered grid)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"Vx = TA(backend)([vx_stream(x, y) for x in grid_vx[1], y in grid_vx[2]]);\nVy = TA(backend)([vy_stream(x, y) for x in grid_vy[1], y in grid_vy[2]]);\nT  = TA(backend)([y for x in xv, y in yv]); # defined at the cell vertices\nV  = Vx, Vy;\ndt = min(\n    dx / MPI.Allreduce(maximum(abs.(Vx)), MPI.MAX, MPI.COMM_WORLD),\n    dy / MPI.Allreduce(maximum(abs.(Vy)), MPI.MAX, MPI.COMM_WORLD)\n)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"Note that now we need to reduce over all the MPI ranks to compute the time-step.","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"We finally initialize the field T on the particles","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"particle_args = pT, = init_cell_arrays(particles, Val(1));","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"and we use the function grid2particle! to interpolate the field T to the particles","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"grid2particle!(pT, xvi, T, particles);","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"Now start the simulation","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"niter = 250\nfor it in 1:niter\n    # advect particles\n    advection!(particles, RungeKutta2(), V, (grid_vx, grid_vy), dt)\n    # move particles in the memory\n    move_particles!(particles, xvi, particle_args) \n    # inject particles if needed\n    inject_particles!(particles, (pT, ), xvi)      \n    # interpolate particles to the grid\n    particle2grid!(T, pT, xvi, particles)          \nend","category":"page"},{"location":"field_advection2D_MPI/#Visualization","page":"Field advection in 2D using MPI","title":"Visualization","text":"","category":"section"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"To visualize the results, we need to allocate a global array T_v and buffer arrays T_nohalo without the overlapping halo (here with width = 1)","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"nx_v     = (size(T, 1) - 2) * dims[1] # global size of `T` without halos\nny_v     = (size(T, 2) - 2) * dims[2] # global size of `T` without halos\nT_v      = zeros(nx_v, ny_v)          # initialize global `T`\nT_nohalo = @zeros(size(T).-2)         # local `T` without overlapping halo","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"Visualization with GLMakie.jl","category":"page"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"using GLMakie\nx_global = range(0, Lx, length=size(T_v,1))\ny_global = range(0, Ly, length=size(T_v,2))\nheatmap(x_global, y_global, T_v)","category":"page"},{"location":"field_advection2D_MPI/#Going-3D","page":"Field advection in 2D using MPI","title":"Going 3D","text":"","category":"section"},{"location":"field_advection2D_MPI/","page":"Field advection in 2D using MPI","title":"Field advection in 2D using MPI","text":"A 3D example using MPI is found in scripts/temperature_advection3D_MPI.jl.","category":"page"},{"location":"#JustPIC.jl","page":"Home","title":"JustPIC.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Particle-in-Cell advection for large scale multi-XPU simulations","category":"page"},{"location":"CellArrays/#Working-with-CellArrays","page":"CellArrays","title":"Working with CellArrays","text":"","category":"section"},{"location":"CellArrays/#Instantiating-a-CellArray","page":"CellArrays","title":"Instantiating a CellArray","text":"","category":"section"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"With the help of ParallelStencil.jl we can easily create a CellArray object. The CellArray object is a container that holds the data of a grid. The data is stored in small nD-arrays, and the grid is divided into cells. Each cell contains a number of elements. The CellArray object is used to store the data of the particles in the simulation.","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"using JustPIC, JustPIC._2D\nusing ParallelStencil\n@init_parallel_stencil(Threads, Float64, 2)","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> ni = (2, 2)\n(2, 2)\n\njulia> ncells = (2,)\n(2,)\n\njulia> x = 20\n20\n\njulia> CA = @fill(x, ni..., celldims = ncells, eltype = Float64) \n2×2 CellArrays.CPUCellArray{StaticArraysCore.SVector{2, Float64}, 2, 1, Float64}:\n [20.0, 20.0]  [20.0, 20.0]\n [20.0, 20.0]  [20.0, 20.0]","category":"page"},{"location":"CellArrays/#Indexing-a-CellArray","page":"CellArrays","title":"Indexing a CellArray","text":"","category":"section"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"We can access to the data of one CellArray by indexing a given grid cell. This will however instantiate a StaticArray object with the data of the cell. ","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> CA[1,1]\n2-element StaticArraysCore.SVector{2, Float64} with indices SOneTo(2):\n 20.0\n 20.0","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"It is however useful to read and mutate the data of the CellArray object directly, without instantiating a StaticArray. For this porpuse, JustPIC exports the macro @index to directly read and mutate the individual elements of the cell. ","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"For example, to read a single element of CA:","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> @index CA[2, 1, 1]\n20.0","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"where, in this case, the first index corresponds to the 2nd element of the data within cell_11 cell. We can mutate the CellArray in a similar way:","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> @index CA[2, 1, 1] = 0.0\n0.0\n\njulia> CA\n2×2 CellArrays.CPUCellArray{StaticArraysCore.SVector{2, Float64}, 2, 1, Float64}:\n [20.0, 0.0]   [20.0, 20.0]\n [20.0, 20.0]  [20.0, 20.0]","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"JustPIC also provides the macro @cell operatig at the cell level:","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> @cell CA[1,1]\n2-element StaticArraysCore.SVector{2, Float64} with indices SOneTo(2):\n 20.0\n 20.0","category":"page"},{"location":"CellArrays/","page":"CellArrays","title":"CellArrays","text":"julia> @cell CA[1,1] = @cell(CA[1,1]) .+ 1\n2-element StaticArraysCore.SVector{2, Float64} with indices SOneTo(2):\n 21.0\n 21.0\n\n julia> CA\n2×2 CellArrays.CPUCellArray{StaticArraysCore.SVector{2, Float64}, 2, 1, Float64}:\n [21.0, 21.0]  [20.0, 20.0]\n [20.0, 20.0]  [20.0, 20.0]","category":"page"},{"location":"marker_chain/#Marker-chain","page":"Marker chain","title":"Marker chain","text":"","category":"section"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"In, e.g., geodynamic modeling is often useful to track interfaces between different materials, such as the topographic profile. We can use the MarkerChain object in JustPIC.jl to define and advect surfaces (not closed-polygons) in two-dimensional models. ","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"We can instantiate a chain object with a given constant elevation h as:","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"chain = init_markerchain(backend, nxcell, min_xcell, max_xcell, xv, h)","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"where backend is the device backend, nxcell is the initial number of makers per cell, min_xcell and max_xcell are the minimum and maximum number of particles allowed per cell, respectively, and xv is the grid corresponding to the vertices of the the grid.","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"We can also fill an existing MarkerChain with a given topographic profile:","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"# create topographic profile\nx      = LinRange(0, 1, 200)\ntopo_x = LinRange(0, 1, 200)\ntopo_y = @. sin(2π*topo_x) * 0.1\n\n# fill the chain with the topographic profile` \nfill_chain!(chain, topo_x, topo_y)","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"Finally, the marker chain can be advected as follows:","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"advect_markerchain!(chain, method, velocity, grid_vxi, dt)","category":"page"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"where method is the time integration method of the advection equation, velocity is a tuple containing the arrays of the velocity field, grid_vxi is a tuple containing the grids of the velocity components on the staggered grid, and t is the time step.","category":"page"},{"location":"marker_chain/#Example","page":"Marker chain","title":"Example","text":"","category":"section"},{"location":"marker_chain/","page":"Marker chain","title":"Marker chain","text":"using JustPIC\nusing JustPIC._2D\nusing GLMakie\n\nconst backend = JustPIC.CPUBackend\n\nfunction expand_range(x::AbstractRange)\n    dx = x[2] - x[1]\n    n = length(x)\n    x1, x2 = extrema(x)\n    xI = round(x1-dx; sigdigits=5)\n    xF = round(x2+dx; sigdigits=5)\n    LinRange(xI, xF, n+2)\nend\n\n# velocity field\nvi_stream(x) =  π*1e-5 * (x - 0.5)\n\n# Initialize domain & grids\nn        = 51\nLx       = Ly = 1.0\n# nodal vertices\nxvi      = xv, yv = LinRange(0, Lx, n), LinRange(0, Ly, n)\ndxi      = dx, dy = xv[2] - xv[1], yv[2] - yv[1]\n# nodal centers\nxc, yc   = LinRange(0+dx/2, Lx-dx/2, n-1), LinRange(0+dy/2, Ly-dy/2, n-1)\n# staggered grid velocity nodal locations\ngrid_vx  = xv, expand_range(yc)\ngrid_vy  = expand_range(xc), yv\ngrid_vxi = grid_vx, grid_vy\n\n# Velocity defined on the grid\nVx       = TA(backend)([-vi_stream(y) for x in grid_vx[1], y in grid_vx[2]]);\nVy       = TA(backend)([ vi_stream(x) for x in grid_vy[1], y in grid_vy[2]]);\nV        = Vx, Vy;\n\n# Initialize marker chain\nnxcell, min_xcell, max_xcell = 12, 6, 24\ninitial_elevation = Ly/2\nchain             = init_markerchain(backend, nxcell, min_xcell, max_xcell, xv, initial_elevation);\nmethod            = RungeKutta2()\n\n# time stepping\ndt       = 200.0\n\nfor _ in 1:25\n    advect_markerchain!(chain, method, V, grid_vxi, dt)\nend\n\n# plotting the chain\nf = Figure()\nax = Axis(f[1, 1])\npoly!(\n    ax,\n    Rect(0, 0, 1, 1),\n    color=:lightgray,\n)\npx = chain.coords[1].data[:];\npy = chain.coords[2].data[:];\nscatter!(px, py, color=:black)\ndisplay(f)","category":"page"}]
}
